{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_numpy_array_data(file_path: str) -> np.array:\n",
    "    \"\"\"\n",
    "    load numpy array data from file\n",
    "    file_path: str location of file to load\n",
    "    return: np.array data loaded\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'rb') as file_obj:\n",
    "            return np.load(file_obj, allow_pickle=True)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_arr = load_numpy_array_data(\"train.npy\")\n",
    "test_arr = load_numpy_array_data(\"test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1005, 10)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0, 1.0, 2.0, ..., 0.0, -0.5367548655561731, 1],\n",
       "       [1.0, 2.0, 1.0, ..., 1.0, -0.07899566203929799, 1],\n",
       "       [4.0, 1.0, 0.0, ..., 0.0, 0.4069639389902209, 0],\n",
       "       ...,\n",
       "       [1.0, 2.0, 1.0, ..., 1.0, 0.34484613861932867, 1],\n",
       "       [4.0, 2.0, 1.0, ..., 1.0, 0.46945076266332375, 1],\n",
       "       [0.0, 0.0, 0.0, ..., 0.0, -0.07899566203929799, 1]], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract first column (index 0)\n",
    "first_column = train_arr[:, 9]\n",
    "\n",
    "# Get unique values and their counts\n",
    "unique, counts = np.unique(first_column, return_counts=True)\n",
    "\n",
    "# Print unique counts\n",
    "for value, count in zip(unique, counts):\n",
    "    print(f\"Value: {value}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(252, 10)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0, 0.0, 1.0, ..., 0.0, -0.1967989106772582, 1],\n",
       "       [3.0, 2.0, 2.0, ..., 0.0, 1.116923977873487, 0],\n",
       "       [2.0, 2.0, 2.0, ..., 1.0, 1.2871211820713415, 0],\n",
       "       ...,\n",
       "       [1.0, 0.0, 0.0, ..., 0.0, -0.5389393369341406, 1],\n",
       "       [0.0, 2.0, 0.0, ..., 0.0, 0.7245827566792103, 1],\n",
       "       [4.0, 1.0, 2.0, ..., 0.0, 1.0257973070629611, 0]], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuro_mf import ModelFactory\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming train_arr and test_arr have already been loaded correctly\n",
    "# Split the data into features (X) and target (y)\n",
    "x_train, y_train = train_arr[:, :-1], train_arr[:, -1]\n",
    "x_test, y_test = test_arr[:, :-1], test_arr[:, -1]\n",
    "# Ensure y_train and y_test are numeric\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "# Create a ModelFactory instance using your model configuration file\n",
    "model_factory = ModelFactory(model_config_path=\"model.yaml\")\n",
    "\n",
    "# Wrap the search process with a progress bar\n",
    "with tqdm(total=100) as pbar:  # You may need to adjust the total to the actual number of iterations\n",
    "    best_model_detail = model_factory.get_best_model(\n",
    "        X=x_train,\n",
    "        y=y_train,\n",
    "        base_accuracy=60\n",
    "    )\n",
    "    # Update the progress bar accordingly during the search process\n",
    "    pbar.update(10)  # Call this as needed to show progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "TARGET_COLUMN = 'treatment'\n",
    "\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "x, y = test_df.drop(TARGET_COLUMN, axis=1), test_df[TARGET_COLUMN]\n",
    "y = y.map({'Yes': 0, 'No': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the model from the pickle file\n",
    "with open('model.pkl', 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "y_hat_best_model = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the model from the pickle file\n",
    "with open('Processing.pkl', 'rb') as file:\n",
    "    preprocessor = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer: LabelEncoder\n",
      "Columns: ['work_interfere', 'benefits', 'care_options', 'anonymity', 'leave', 'Gender', 'remote_work', 'family_history']\n",
      "Transformer: Transformer\n",
      "Columns: ['Age']\n"
     ]
    }
   ],
   "source": [
    "transformers = preprocessor.transformers\n",
    "for name, transformer, columns in transformers:\n",
    "    print(f\"Transformer: {name}\")\n",
    "    print(f\"Columns: {columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories for 'work_interfere': [\"Don't know\" 'Never' 'Often' 'Rarely' 'Sometimes']\n"
     ]
    }
   ],
   "source": [
    "# Now access the fitted OrdinalEncoder\n",
    "ordinal_encoder = preprocessor.named_transformers_['LabelEncoder']\n",
    "\n",
    "# Get the categories learned by the OrdinalEncoder\n",
    "ordinal_categories = ordinal_encoder.categories_\n",
    "\n",
    "# Find the index of 'work_interfere' column in the encoder\n",
    "work_interfere_index = 0\n",
    "\n",
    "# Get the categories for 'work_interfere'\n",
    "work_interfere_labels = ordinal_categories[work_interfere_index]\n",
    "print(f\"Categories for 'work_interfere': {work_interfere_labels}\")\n",
    "\n",
    "# You can then transform the test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Mental_Health.pipeline.prediction_pipeline import MentalhealthData, MentalHealthClassifier\n",
    "\n",
    "\n",
    "\n",
    "mentalhealth_data = MentalhealthData(\n",
    "    age=29,\n",
    "    gender='male',\n",
    "    family_history=\"Yes\",\n",
    "    benefits=\"Don't know\",\n",
    "    care_options=\"Not sure\",\n",
    "    anonymity=\"Don't know\",\n",
    "    leave=\"Very easy\",\n",
    "    work_interfere=\"Don't know\",\n",
    "    remote_work = \"No\"\n",
    ")\n",
    "\n",
    "mh_data = mentalhealth_data.get_mentalhealth_input_data_frame()\n",
    "\n",
    "model_predictor = MentalHealthClassifier()\n",
    "\n",
    "value = model_predictor.predict(dataframe=mh_data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
